{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark of sorted lists & sets implementations \n",
    "\n",
    "First, you may need to install the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sortedcontainers>=2.2.2\"\n",
    "!pip install \"blist>=1.3.6\"\n",
    "!pip install \"tqdm>=4.39.0\"\n",
    "!pip install \"Pympler>=0.8\"\n",
    "!pip install \"py-cpuinfo>=6.0.0\"\n",
    "!pip install \"pyroaring>=0.2.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have problems with the installation of pyroaring on macOS, run `brew install gcc@10`, `export CC=gcc-10 CXX=g++-10`, and then `pip install pyroaring`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Set up the experiments\n",
    "\n",
    "Here we set the `number` of times an operation is executed, the data `sizes` that must be tested, a function `gen_list_data` to generate data for the sorted list structures, and a function `gen_set_data` to generate data (without duplicates) for the set structures. Note that pyroaring requires `gen_set_data` to output 32-bit unsigned integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "number = 50000\n",
    "sizes = [10 ** x for x in range(2, 8)]\n",
    "gen_list_data = lambda s: np.sort(np.random.normal(0, 2 ** 40, s).astype(int)).tolist()\n",
    "gen_set_data = lambda s: sorted(random.sample(range(min(2 ** 32, s * 1000)) , s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the **list** structures and the operations to benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pympler.asizeof import asizeof\n",
    "\n",
    "import blist\n",
    "import pygm\n",
    "import pickle\n",
    "import sortedcontainers\n",
    "\n",
    "list_structures = {\n",
    "    'sortedcontainers.SortedList' : {\n",
    "        'ctor' : lambda data: sortedcontainers.SortedList(data),\n",
    "        'mem' : lambda o : asizeof(o)\n",
    "    },\n",
    "    'pygm.SortedList' : {\n",
    "        'ctor' : lambda data: pygm.SortedList(data, 'q'),\n",
    "        'mem' : lambda o: o.stats()['data size'] + o.stats()['index size']\n",
    "    },\n",
    "    'blist.sortedlist' : {\n",
    "        'ctor' : lambda data: blist.sortedlist(data),\n",
    "        'mem' : lambda o : len(pickle.dumps(o, -1)) + o._blist.__sizeof__()\n",
    "    }\n",
    "}\n",
    "\n",
    "list_experiments = defaultdict(dict)\n",
    "for struct in list_structures:\n",
    "    list_experiments['__init__'][struct] = {\n",
    "        'func' : lambda _, data, ctor=list_structures[struct]['ctor']: ctor(data),\n",
    "        'args' : lambda data: data,\n",
    "        'limit' : 1\n",
    "    }\n",
    "    \n",
    "    list_experiments['__contains__ âŸº x in list'][struct] = {\n",
    "        'func' : '__contains__',\n",
    "        'args' : lambda data: random.choice(data)\n",
    "    }\n",
    "    \n",
    "    list_experiments['__getitem__ âŸº list[i]'][struct] = {\n",
    "        'func' : '__getitem__',\n",
    "        'args' : lambda data: random.randint(0, len(data) - 1)\n",
    "    }\n",
    "    \n",
    "    list_experiments['index'][struct] = {\n",
    "        'func' : 'index',\n",
    "        'args' : lambda data: data[random.randint(0, len(data) - 1)]\n",
    "    }\n",
    "    \n",
    "    list_experiments['count'][struct] = {\n",
    "        'func' : 'count',\n",
    "        'args' : lambda data: random.choice(data)\n",
    "    }\n",
    "    \n",
    "    list_experiments['bisect_left'][struct] = {\n",
    "        'func' : 'bisect_left',\n",
    "        'args' : lambda data: random.randint(data[0], data[len(data) - 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the **set** structures and the operations to benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyroaring\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def get_set_data(data, factor):\n",
    "    n = max(int(len(data) * factor), 10) // 2\n",
    "    i = random.randint(0, len(data) - n)\n",
    "    return list(range(i, i + n)) + list(random.sample(data, n))\n",
    "\n",
    "\n",
    "set_structures = {\n",
    "    'sortedcontainers.SortedSet' : {\n",
    "        'ctor' : lambda data: sortedcontainers.SortedSet(data),\n",
    "        'mem' : lambda o : asizeof(o)\n",
    "    },\n",
    "    'pygm.SortedSet' : {\n",
    "        'ctor' : lambda data: pygm.SortedSet(data, 'I'),\n",
    "        'mem' : lambda o: o.stats()['data size'] + o.stats()['index size']\n",
    "    },\n",
    "    'pyroaring.BitMap' : {\n",
    "        'ctor' : lambda data: pyroaring.BitMap(data),\n",
    "        'mem' : lambda o: o.__sizeof__()\n",
    "    },\n",
    "}\n",
    "\n",
    "override_index = {'pyroaring.BitMap': lambda self, x: self.rank(x)}\n",
    "override_bisect = {'pyroaring.BitMap': lambda self, x: self.rank(x)}\n",
    "override_args = {\n",
    "    'sortedcontainers.SortedSet': lambda f, data: sortedcontainers.SortedSet(get_set_data(data, f)),\n",
    "    'pygm.SortedSet': lambda f, data: pygm.SortedSet(get_set_data(data, f), 'I'),\n",
    "    'pyroaring.BitMap': lambda f, data: pyroaring.BitMap(get_set_data(data, f)),\n",
    "}\n",
    "\n",
    "set_experiments = defaultdict(dict)\n",
    "for struct in set_structures:\n",
    "    set_experiments['__init__'][struct] = {\n",
    "        'func' : lambda _, data, ctor=set_structures[struct]['ctor']: ctor(data),\n",
    "        'args' : lambda data: data,\n",
    "        'limit' : 1\n",
    "    }\n",
    "    \n",
    "    set_experiments['__contains__ âŸº x in set'][struct] = {\n",
    "        'func' : '__contains__',\n",
    "        'args' : lambda data: random.choice(data)\n",
    "    }\n",
    "    \n",
    "    set_experiments['__getitem__ âŸº set[i]'][struct] = {\n",
    "        'func' : '__getitem__',\n",
    "        'args' : lambda data: random.randint(0, len(data) - 1)\n",
    "    }\n",
    "    \n",
    "    set_experiments['index'][struct] = {\n",
    "        'func' : override_index.get(struct, 'index'),\n",
    "        'args' : lambda data: data[random.randint(0, len(data) - 1)]\n",
    "    }\n",
    "    \n",
    "    set_experiments['bisect_left'][struct] = {\n",
    "        'func' : override_bisect.get(struct, 'bisect_left'),\n",
    "        'args' : lambda data: random.randint(data[0], data[len(data) - 1])\n",
    "    }\n",
    "    \n",
    "    for op in ['union', 'difference', 'intersection', 'symmetric_difference']:        \n",
    "        set_experiments[op + ' (small)'][struct] = {\n",
    "            'func' : op,\n",
    "            'args' : partial(override_args[struct], 1 / 100),\n",
    "            'limit' : 1\n",
    "        }\n",
    "\n",
    "        set_experiments[op + ' (medium)'][struct] = {\n",
    "            'func' : op,\n",
    "            'args' : partial(override_args[struct], 1 / 10),\n",
    "            'limit' : 1\n",
    "        }\n",
    "\n",
    "        set_experiments[op + ' (large)'][struct] = {\n",
    "            'func' : op,\n",
    "            'args' : partial(override_args[struct], 9 / 10),\n",
    "            'limit' : 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â³ Measure the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def run_exp(structures, experiments, data_generator):\n",
    "    mem_results = defaultdict(list)\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "    pbar = tqdm(total=len(sizes) * len(structures) * len(experiments))\n",
    "\n",
    "    for size in sizes:\n",
    "        data = data_generator(size)\n",
    "        for struct in structures:\n",
    "            gc.collect()\n",
    "            obj = structures[struct]['ctor'](data)\n",
    "            mem = structures[struct]['mem'](obj)\n",
    "            mem_results[struct].append(mem)\n",
    "            \n",
    "            for exp in experiments:\n",
    "                info = experiments[exp][struct]\n",
    "                limit = info.get('limit', number)\n",
    "                args = info['args']\n",
    "                func = info['func']\n",
    "                func = getattr(obj, func) if isinstance(func, str) else partial(func, obj)\n",
    "\n",
    "                sec = 0\n",
    "                batch_size = min(1000, limit)\n",
    "                for _ in range(0, limit, batch_size):\n",
    "                    batch = [args(data) for _ in range(batch_size)]\n",
    "                    gc.disable()\n",
    "                    t0 = time()\n",
    "                    for x in batch:\n",
    "                        func(x)\n",
    "                    t1 = time()\n",
    "                    sec += t1 - t0\n",
    "                    gc.enable()\n",
    "                \n",
    "                results[exp][struct].append(sec / ((limit // batch_size) * batch_size) )\n",
    "                pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return results, mem_results\n",
    "\n",
    "\n",
    "list_results, mem_list_results = run_exp(list_structures, list_experiments, gen_list_data)\n",
    "set_results, mem_set_results = run_exp(set_structures, set_experiments, gen_set_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Plot performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def platform_info():\n",
    "    import platform as p\n",
    "    from cpuinfo import get_cpu_info\n",
    "    return '%s  ~^~  %s  ~^~  %s %s (%s)' % (\n",
    "        get_cpu_info()['brand_raw'],\n",
    "        p.platform(),\n",
    "        p.python_implementation(), \n",
    "        p.python_version(),\n",
    "        p.python_compiler(),)\n",
    "\n",
    "\n",
    "def plot(results, structures, title):\n",
    "    colors = ['C%d' % i for i in range(10)]\n",
    "    markers = ['o', '^', '>', 's', '<', 'p', 'P', 'D']\n",
    "    ncols = min(3, ceil(len(results) ** 0.5))\n",
    "    nrows = ceil(len(results) / ncols)\n",
    "    figsize = (5.3 * ncols, 4.5 * nrows)\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, squeeze=False,\n",
    "                            sharex=False, sharey=False, constrained_layout=True)\n",
    "    fig.suptitle(title, fontsize=20, weight='medium')\n",
    "    fig.text(0.5, -0.5 / figsize[1], platform_info(), fontsize=10, family='monospace',\n",
    "             ha='center')\n",
    "\n",
    "    for (exp_i, (exp, ax)) in enumerate(zip(results, axs.flat)):\n",
    "        for i, struct in enumerate(structures):\n",
    "            ax.plot(sizes, results[exp][struct],\n",
    "                    label=struct, color=colors[i], marker=markers[i])\n",
    "\n",
    "        if exp_i >= ncols * (nrows - 1):\n",
    "            ax.set_xlabel('Data size')\n",
    "        if exp_i % ncols == 0:\n",
    "            ax.set_ylabel('Time')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.set_title(exp)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.yaxis.set_major_formatter(ticker.EngFormatter(unit='s'))\n",
    "    \n",
    "    #plt.savefig(title + '.svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot(list_results, list_structures, 'Performance of sorted lists')\n",
    "plot(set_results, set_structures, 'Performance of sorted sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Plot the memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mem(results, structures, title):\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    bars = len(sizes) * len(structures)\n",
    "    x = np.arange(len(sizes))\n",
    "    group_spacing = 1.2\n",
    "    width = len(sizes) / (bars * group_spacing)\n",
    "    fig.suptitle(title, fontsize=18, weight='medium')\n",
    "\n",
    "    for i, struct in enumerate(structures):\n",
    "        offset = x + width * i - 0.5 * width * (len(structures) - 1)\n",
    "        ax.bar(offset, results[struct], label=struct, width=width)\n",
    "\n",
    "    fmt = ticker.ScalarFormatter(useMathText=True)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['$%s$' % fmt.format_data(x) for x in sizes])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Data size')\n",
    "    ax.set_ylabel('Memory')\n",
    "    ax.yaxis.set_major_formatter(ticker.EngFormatter(unit='B'))\n",
    "    ax.legend()\n",
    "    \n",
    "    #plt.savefig(title + '.svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_mem(mem_list_results, list_structures, 'Memory usage of sorted lists')\n",
    "plot_mem(mem_set_results, set_structures, 'Memory usage of sorted sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore PGM segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_segments(pgm_idx, level=0):\n",
    "    \n",
    "    seg0 = pgm_idx.segment(level, 0)\n",
    "    plt.title(f\"level={level} eps={int(seg0['epsilon'])}\")\n",
    "    \n",
    "    segments_count = pgm_idx.num_segments(level)\n",
    "    for seg_num in range(0, segments_count):\n",
    "        seg = pgm_idx.segment(level, seg_num)\n",
    "\n",
    "        x_start = seg['key']\n",
    "\n",
    "        if seg_num == segments_count - 1:\n",
    "            x_stop = pgm_idx[-1]\n",
    "        else:\n",
    "            x_stop = pgm_idx.segment(level, seg_num+1)['key']\n",
    "\n",
    "        x_vals = np.array([ x_start, x_stop ])\n",
    "        y_vals = seg['intercept'] + seg['slope'] * (x_vals - seg['key'])\n",
    "\n",
    "        eps = seg['epsilon']\n",
    "        plt.gca().fill_between(x_vals, y_vals - eps, y_vals + eps, alpha=0.5, label=f'segment {seg_num}')\n",
    "\n",
    "    if level > 0:\n",
    "        prev_level = level - 1\n",
    "        prev_level_segments_count = pgm_idx.num_segments(prev_level)\n",
    "        intercepts = []\n",
    "        keys = []\n",
    "        for seg_num in range(0, prev_level_segments_count):\n",
    "            seg = pgm_idx.segment(prev_level, seg_num)\n",
    "            intercepts.append(seg['intercept'])\n",
    "            keys.append(seg['key'])\n",
    "\n",
    "        plt.scatter(keys, range(len(keys)), marker='X', label=f'level {prev_level} keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygm_idx = pygm.SortedList(gen_list_data(1000), epsilon=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segments(pygm_idx, level=0)\n",
    "\n",
    "plt.scatter(pygm_idx, range(len(pygm_idx)), s=1, alpha=0.1, color='blue')\n",
    "\n",
    "plt.gcf().set_size_inches((15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segments(pygm_idx, level=1)\n",
    "plt.gcf().set_size_inches((15,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
